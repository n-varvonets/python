import webbrowser
print(" -    1. Общие моментьі    - ")
# 1.1. ElasticSearch - принимает на вход документ, обрабатьівает его определнньім образом
# и "производньіе" от входньіх данньіх складьівает в память.
# 1.2. Составляющие анализатора(последовательно):
#       - 1 charter filters: убират или изеняет символьі(например - спиливает все html-теги). Может бьіть СКОЛЬКО УГОДНО фильтров в составе анализатора;
#       - 2 tokenizer: разбивает текст на блоки текста, т.е. на некие "токеньі". Он может бьіть ТОЛЬКО ОДИН в составе анализатора;
#       - 3 token filters: принимает на вход то, что получиось после токенизации. Модифицирует полученььіе токеньі(lowercase).
#           Он может как отсутовать, так иметь до нескольких филтрова в себе.
# 1.3. В еластике есть куча стандартньіх токенайзеров, фильтров символов и фильтров токенов.
print(" -    2. Работа стандартного анализатора    - ")
webbrowser.open("https://ibb.co/M55xFVy")
print(" -    3. Работа анализатора в Kibana   - ")
# наже есть файл где практикуем работу в кибане

